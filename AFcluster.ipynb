{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgU7dhxA0fpweoIBQyfawr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HWaymentSteele/AF_Cluster/blob/main/AFcluster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AF-cluster (in Colab form!)\n",
        "\n",
        "Last updated H Wayment-Steele, Jan 2023\n",
        "\n",
        "### To cluster (subsample) a big MSA:\n",
        "\n",
        "1. Upload the big MSA.\n",
        "\n",
        "2. Run the \"**Cluster MSA**\" cell, changing `EX` to your desired keyword and the name of your input a3m. MSAs will be written to \"subsampled_MSAs\". \n",
        "\n",
        "3. Uncomment the correct path (containing `/content/subsampled_MSAs` ) in the \"**Run Models**\" cell, and run it.\n",
        "\n",
        "4. Output PDBs will be saved in `output`.\n",
        "\n",
        "### If you have an existing set of subsampled MSAs to run:\n",
        "1. Upload a directory of MSA files to run.\n",
        "\n",
        "2. Change the `AFcluster/data..\\*a3m` path in the \"**Run Models**\" cell and run it.\n",
        "\n",
        "3. Output PDBs will be saved in `output`."
      ],
      "metadata": {
        "id": "4rYBJDJ4FwGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Setup dependencies\n",
        "%%bash\n",
        "\n",
        "if [ ! -d params ]; then\n",
        "  mkdir params\n",
        "  curl -fsSL https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar | tar x -C params\n",
        "fi\n",
        "\n",
        "if [ ! -d AFcluster ];then\n",
        "  git clone https://github.com/HWaymentSteele/AFcluster.git\n",
        "fi\n",
        "\n",
        "if [ ! -d alphafold ]; then\n",
        "  git clone https://github.com/deepmind/alphafold.git\n",
        "  ! pip -q install ml-collections dm-haiku biopython==1.81\n",
        "fi\n",
        "\n",
        "if [ ! -d output ]; then\n",
        "  mkdir output\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GHTu08UC4seL",
        "outputId": "d5640a8a-94fc-4a25-b72a-cf4318bdec50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'AFcluster'...\n",
            "Checking out files:  20% (2731/13504)   \rChecking out files:  21% (2836/13504)   \rChecking out files:  22% (2971/13504)   \rChecking out files:  23% (3106/13504)   \rChecking out files:  24% (3241/13504)   \rChecking out files:  25% (3376/13504)   \rChecking out files:  26% (3512/13504)   \rChecking out files:  27% (3647/13504)   \rChecking out files:  28% (3782/13504)   \rChecking out files:  29% (3917/13504)   \rChecking out files:  30% (4052/13504)   \rChecking out files:  31% (4187/13504)   \rChecking out files:  32% (4322/13504)   \rChecking out files:  33% (4457/13504)   \rChecking out files:  34% (4592/13504)   \rChecking out files:  35% (4727/13504)   \rChecking out files:  36% (4862/13504)   \rChecking out files:  37% (4997/13504)   \rChecking out files:  38% (5132/13504)   \rChecking out files:  39% (5267/13504)   \rChecking out files:  40% (5402/13504)   \rChecking out files:  41% (5537/13504)   \rChecking out files:  42% (5672/13504)   \rChecking out files:  43% (5807/13504)   \rChecking out files:  44% (5942/13504)   \rChecking out files:  45% (6077/13504)   \rChecking out files:  46% (6212/13504)   \rChecking out files:  46% (6266/13504)   \rChecking out files:  47% (6347/13504)   \rChecking out files:  48% (6482/13504)   \rChecking out files:  49% (6617/13504)   \rChecking out files:  49% (6742/13504)   \rChecking out files:  50% (6752/13504)   \rChecking out files:  51% (6888/13504)   \rChecking out files:  52% (7023/13504)   \rChecking out files:  52% (7054/13504)   \rChecking out files:  53% (7158/13504)   \rChecking out files:  54% (7293/13504)   \rChecking out files:  54% (7357/13504)   \rChecking out files:  55% (7428/13504)   \rChecking out files:  56% (7563/13504)   \rChecking out files:  57% (7698/13504)   \rChecking out files:  57% (7703/13504)   \rChecking out files:  58% (7833/13504)   \rChecking out files:  59% (7968/13504)   \rChecking out files:  59% (8047/13504)   \rChecking out files:  60% (8103/13504)   \rChecking out files:  61% (8238/13504)   \rChecking out files:  62% (8373/13504)   \rChecking out files:  63% (8508/13504)   \rChecking out files:  64% (8643/13504)   \rChecking out files:  65% (8778/13504)   \rChecking out files:  66% (8913/13504)   \rChecking out files:  67% (9048/13504)   \rChecking out files:  68% (9183/13504)   \rChecking out files:  69% (9318/13504)   \rChecking out files:  70% (9453/13504)   \rChecking out files:  71% (9588/13504)   \rChecking out files:  72% (9723/13504)   \rChecking out files:  73% (9858/13504)   \rChecking out files:  74% (9993/13504)   \rChecking out files:  75% (10128/13504)   \rChecking out files:  76% (10264/13504)   \rChecking out files:  77% (10399/13504)   \rChecking out files:  78% (10534/13504)   \rChecking out files:  78% (10641/13504)   \rChecking out files:  79% (10669/13504)   \rChecking out files:  80% (10804/13504)   \rChecking out files:  81% (10939/13504)   \rChecking out files:  82% (11074/13504)   \rChecking out files:  83% (11209/13504)   \rChecking out files:  84% (11344/13504)   \rChecking out files:  85% (11479/13504)   \rChecking out files:  86% (11614/13504)   \rChecking out files:  87% (11749/13504)   \rChecking out files:  88% (11884/13504)   \rChecking out files:  89% (12019/13504)   \rChecking out files:  90% (12154/13504)   \rChecking out files:  91% (12289/13504)   \rChecking out files:  92% (12424/13504)   \rChecking out files:  93% (12559/13504)   \rChecking out files:  94% (12694/13504)   \rChecking out files:  95% (12829/13504)   \rChecking out files:  96% (12964/13504)   \rChecking out files:  97% (13099/13504)   \rChecking out files:  98% (13234/13504)   \rChecking out files:  98% (13347/13504)   \rChecking out files:  99% (13369/13504)   \rChecking out files: 100% (13504/13504)   \rChecking out files: 100% (13504/13504), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "NyuGtGrG3Zc0",
        "outputId": "6adf642e-c011-4bde-dae8-7a27d645a43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/Bio/Data/SCOPData.py:18: BiopythonDeprecationWarning: The 'Bio.Data.SCOPData' module will be deprecated in a future release of Biopython in favor of 'Bio.Data.PDBData.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## Define functions to run AlphaFold\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import hashlib\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import re\n",
        "import subprocess\n",
        "from glob import glob\n",
        "\n",
        "sys.path.append('alphafold')\n",
        "\n",
        "from alphafold.model import model, config, data\n",
        "from alphafold.data import parsers, pipeline\n",
        "from alphafold.common import protein\n",
        "\n",
        "\"\"\"\n",
        "Create an AlphaFold model runner\n",
        "name -- The name of the model to get the parameters from. Options: model_[1-5]\n",
        "\"\"\"\n",
        "\n",
        "def make_model_runner(model_num=3, recycles=1, deterministic=True):\n",
        "  model_name = 'model_%d_ptm' % model_num\n",
        "  cfg = config.model_config(model_name)      \n",
        "\n",
        "  cfg.data.common.num_recycle = recycles\n",
        "  cfg.model.num_recycle = recycles\n",
        "  cfg.data.eval.num_ensemble = 1\n",
        "  if deterministic:\n",
        "    cfg.data.eval.masked_msa_replace_fraction = 0.0\n",
        "    cfg.model.global_config.deterministic = True\n",
        "  params = data.get_model_haiku_params(model_name, '.')\n",
        "\n",
        "  return model.RunModel(cfg, params)\n",
        "\n",
        "def make_processed_feature_dict(runner, a3m_file, name=\"test\", seed=0):\n",
        "  feature_dict = {}\n",
        "\n",
        "  # assumes sequence is first entry in msa\n",
        "  with open(a3m_file,'r') as msa_fil:\n",
        "    sequence = msa_fil.read().splitlines()[1].strip()\n",
        "\n",
        "  feature_dict.update(pipeline.make_sequence_features(sequence, name, len(sequence)))\n",
        "\n",
        "  with open(a3m_file,'r') as msa_fil:\n",
        "    msa = pipeline.parsers.parse_a3m(msa_fil.read())\n",
        "\n",
        "  feature_dict.update(pipeline.make_msa_features([msa]))\n",
        "  processed_feature_dict = runner.process_features(feature_dict, random_seed=seed)\n",
        "\n",
        "  return processed_feature_dict\n",
        "\n",
        "\"\"\"\n",
        "Package AlphaFold's output into an easy-to-use dictionary\n",
        "prediction_result - output from running AlphaFold on an input dictionary\n",
        "processed_feature_dict -- The dictionary passed to AlphaFold as input. Returned by `make_processed_feature_dict`.\n",
        "\"\"\"\n",
        "def parse_results(prediction_result, processed_feature_dict):\n",
        "  b_factors = prediction_result['plddt'][:,None] * prediction_result['structure_module']['final_atom_mask']  \n",
        "  dist_bins = jax.numpy.append(0,prediction_result[\"distogram\"][\"bin_edges\"])\n",
        "  dist_mtx = dist_bins[prediction_result[\"distogram\"][\"logits\"].argmax(-1)]\n",
        "  contact_mtx = jax.nn.softmax(prediction_result[\"distogram\"][\"logits\"])[:,:,dist_bins < 8].sum(-1)\n",
        "\n",
        "  out = {\"unrelaxed_protein\": protein.from_prediction(processed_feature_dict, prediction_result, b_factors=b_factors),\n",
        "        \"plddt\": prediction_result['plddt'],\n",
        "        \"pLDDT\": prediction_result['plddt'].mean(),\n",
        "        \"dists\": dist_mtx,\n",
        "        \"adj\": contact_mtx}\n",
        "\n",
        "  out.update({\"pae\": prediction_result['predicted_aligned_error'],\n",
        "              \"pTMscore\": prediction_result['ptm']})\n",
        "  return out\n",
        "\n",
        "def write_results(result, pdb_out_path):\n",
        "  plddt = float(result['pLDDT'])\n",
        "  ptm = float(result[\"pTMscore\"])\n",
        "  print('plddt: %.3f' % plddt)\n",
        "  print('ptm  : %.3f' % ptm)\n",
        "\n",
        "  pdb_lines = protein.to_pdb(result[\"unrelaxed_protein\"])\n",
        "  with open(pdb_out_path, 'w') as f:\n",
        "    f.write(pdb_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cluster MSA**"
      ],
      "metadata": {
        "id": "Bjio2MR0Hrsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip -q install polyleven\n",
        "\n",
        "python AFcluster/scripts/ClusterMSA.py EX -i AFcluster/data_sep2022/00_KaiB/2QKEE_colabfold.a3m -o subsampled_MSAs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1u5KsffHw5I",
        "outputId": "0e9305b5-8b40-432f-d58b-f034518ad117"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EX\n",
            "1021 seqs removed for containing more than 25% gaps, 7137 remaining\n",
            "eps\tn_clusters\tn_not_clustered\n",
            "3.00\t4\t1755\n",
            "3.50\t6\t1743\n",
            "4.00\t7\t1733\n",
            "4.50\t13\t1687\n",
            "5.00\t18\t1656\n",
            "5.50\t38\t1554\n",
            "6.00\t41\t1479\n",
            "6.50\t57\t1268\n",
            "7.00\t70\t1066\n",
            "7.50\t79\t771\n",
            "8.00\t65\t560\n",
            "8.50\t58\t324\n",
            "9.00\t25\t174\n",
            "9.50\t7\t63\n",
            "10.00\t2\t20\n",
            "10.50\t1\t0\n",
            "Selected eps=7.50\n",
            "7137 total seqs\n",
            "245 clusters, 1754 of 7137 not clustered (0.25)\n",
            "avg identity to query of unclustered: 0.38\n",
            "avg identity to query of clustered: 0.43\n",
            "writing 10 size-10 uniformly sampled clusters\n",
            "writing 10 size-100 uniformly sampled clusters\n",
            "wrote clustering data to subsampled_MSAs/EX_clustering_assignments.tsv\n",
            "wrote cluster metadata to subsampled_MSAs/EX_cluster_metadata.tsv\n",
            "Saved this output to EX.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_recycles = 3\n",
        "model_number = 3\n",
        "seed=0\n",
        "name='KaiB_TE'\n",
        "\n",
        "runner = make_model_runner(model_num=model_number, recycles=n_recycles)\n",
        "\n",
        "subsampled_msas = glob('AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/*a3m')\n",
        "#subsampled_msas = glob('subsampled_MSAs/*a3m')\n",
        "\n",
        "for fil in subsampled_msas:\n",
        "  print(fil)\n",
        "  features = make_processed_feature_dict(runner, fil, seed=seed)\n",
        "  result = parse_results(runner.predict(features, random_seed=seed), features)\n",
        "  write_results(result, 'output/' + os.path.basename(fil).replace('.a3m','.pdb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BdXYiN5m5IpJ",
        "outputId": "ae44bd14-555c-43c3-fa2c-8df1c24485a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U10-103.a3m\n",
            "plddt: 68.423\n",
            "ptm  : 0.492\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U100-476.a3m\n",
            "plddt: 87.045\n",
            "ptm  : 0.763\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U100-120.a3m\n",
            "plddt: 84.589\n",
            "ptm  : 0.740\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U10-488.a3m\n",
            "plddt: 85.976\n",
            "ptm  : 0.752\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_06.a3m\n",
            "plddt: 66.378\n",
            "ptm  : 0.486\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U100-190.a3m\n",
            "plddt: 88.812\n",
            "ptm  : 0.802\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_130.a3m\n",
            "plddt: 65.222\n",
            "ptm  : 0.498\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U10-462.a3m\n",
            "plddt: 81.327\n",
            "ptm  : 0.684\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U100-069.a3m\n",
            "plddt: 90.948\n",
            "ptm  : 0.833\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U10-035.a3m\n",
            "plddt: 88.240\n",
            "ptm  : 0.795\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U10-456.a3m\n",
            "plddt: 86.307\n",
            "ptm  : 0.753\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_157.a3m\n",
            "plddt: 61.290\n",
            "ptm  : 0.426\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_318.a3m\n",
            "plddt: 82.347\n",
            "ptm  : 0.717\n",
            "AFcluster/data_sep2022/00_KaiB/kaib_dbscan_msas/2QKEE_U10-390.a3m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8f3bd3cb33d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_processed_feature_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mwrite_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.a3m'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.pdb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/alphafold/alphafold/model/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feat, random_seed)\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[1;32m    166\u001b[0m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# This block is to ensure benchmark timings are accurate. Some blocking is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DK7WDBt-AY-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
